Epoch: 1, train_loss: 9460.711910359654, val_loss: 10348.533367893348, micro F1: 0.12714550507613845, F1 sum: 0.14272236638720034Best F1 sum model was saved at epoch 1! F1 sum best: 0.14272236638720034 at step 1; micro F1 best: 0.0 at step 0 
Best micro F1 model was saved at epoch 1! F1 sum best: 0.14272236638720034 at step 1; micro F1 best: 0.12714550507613845 at step 1 
Epoch: 2, train_loss: 7678.549012089155, val_loss: 8795.455014333129, micro F1: 0.12180472351145302, F1 sum: 0.14602119560399748Best F1 sum model was saved at epoch 2! F1 sum best: 0.14602119560399748 at step 2; micro F1 best: 0.12714550507613845 at step 1 
Epoch: 3, train_loss: 6816.641019396328, val_loss: 7299.199762443702, micro F1: 0.20798130554288338, F1 sum: 0.24646123891408628Best F1 sum model was saved at epoch 3! F1 sum best: 0.24646123891408628 at step 3; micro F1 best: 0.12714550507613845 at step 1 
Best micro F1 model was saved at epoch 3! F1 sum best: 0.24646123891408628 at step 3; micro F1 best: 0.20798130554288338 at step 3 
Epoch: 4, train_loss: 6187.588285174267, val_loss: 6874.160538815582, micro F1: 0.18865041068609875, F1 sum: 0.2279342933649957Model was Not saved at epoch 4! F1 sum best: 0.24646123891408628 at step 3; micro F1 best: 0.20798130554288338 at step 3 
Epoch: 5, train_loss: 5665.233076889786, val_loss: 7286.147406557575, micro F1: 0.17016836271354804, F1 sum: 0.20649233659383553Model was Not saved at epoch 5! F1 sum best: 0.24646123891408628 at step 3; micro F1 best: 0.20798130554288338 at step 3 
Epoch: 6, train_loss: 5337.633937984788, val_loss: 6622.300128219649, micro F1: 0.23910775034770873, F1 sum: 0.2875320158671305Best F1 sum model was saved at epoch 6! F1 sum best: 0.2875320158671305 at step 6; micro F1 best: 0.20798130554288338 at step 3 
Best micro F1 model was saved at epoch 6! F1 sum best: 0.2875320158671305 at step 6; micro F1 best: 0.23910775034770873 at step 6 
Epoch: 7, train_loss: 5013.141002836695, val_loss: 6286.842355815073, micro F1: 0.2317316722267909, F1 sum: 0.28365074576169413Model was Not saved at epoch 7! F1 sum best: 0.2875320158671305 at step 6; micro F1 best: 0.23910775034770873 at step 6 
Epoch: 8, train_loss: 4752.573857133001, val_loss: 6514.863375341521, micro F1: 0.23165950559644746, F1 sum: 0.2864638842804463Model was Not saved at epoch 8! F1 sum best: 0.2875320158671305 at step 6; micro F1 best: 0.23910775034770873 at step 6 
Epoch: 9, train_loss: 4502.081661646599, val_loss: 6591.748647624626, micro F1: 0.2850514543776323, F1 sum: 0.36313866159925967Best F1 sum model was saved at epoch 9! F1 sum best: 0.36313866159925967 at step 9; micro F1 best: 0.23910775034770873 at step 6 
Best micro F1 model was saved at epoch 9! F1 sum best: 0.36313866159925967 at step 9; micro F1 best: 0.2850514543776323 at step 9 
Epoch: 10, train_loss: 4370.850736363152, val_loss: 6536.115667161842, micro F1: 0.3511279462269158, F1 sum: 0.449419798851477Best F1 sum model was saved at epoch 10! F1 sum best: 0.449419798851477 at step 10; micro F1 best: 0.2850514543776323 at step 9 
Best micro F1 model was saved at epoch 10! F1 sum best: 0.449419798851477 at step 10; micro F1 best: 0.3511279462269158 at step 10 
Epoch: 11, train_loss: 4214.780800459175, val_loss: 5971.293078036979, micro F1: 0.24791480493549897, F1 sum: 0.3132145322900783Model was Not saved at epoch 11! F1 sum best: 0.449419798851477 at step 10; micro F1 best: 0.3511279462269158 at step 10 
Epoch: 12, train_loss: 4023.615278086616, val_loss: 7379.7315048674745, micro F1: 0.14783400497059726, F1 sum: 0.18068252777775343Model was Not saved at epoch 12! F1 sum best: 0.449419798851477 at step 10; micro F1 best: 0.3511279462269158 at step 10 
Epoch: 13, train_loss: 3943.7776633270923, val_loss: 5533.710349506388, micro F1: 0.3077572875819972, F1 sum: 0.3955946342013703Model was Not saved at epoch 13! F1 sum best: 0.449419798851477 at step 10; micro F1 best: 0.3511279462269158 at step 10 
Epoch: 14, train_loss: 3848.0972656114714, val_loss: 5714.629847789183, micro F1: 0.36633959270475314, F1 sum: 0.48778434439521634Best F1 sum model was saved at epoch 14! F1 sum best: 0.48778434439521634 at step 14; micro F1 best: 0.3511279462269158 at step 10 
Best micro F1 model was saved at epoch 14! F1 sum best: 0.48778434439521634 at step 14; micro F1 best: 0.36633959270475314 at step 14 
Epoch: 15, train_loss: 3740.452188448193, val_loss: 5227.324060785274, micro F1: 0.343990435670518, F1 sum: 0.45452412452557384Model was Not saved at epoch 15! F1 sum best: 0.48778434439521634 at step 14; micro F1 best: 0.36633959270475314 at step 14 
Epoch: 16, train_loss: 3643.2957995538286, val_loss: 5020.395741836789, micro F1: 0.36871218439767595, F1 sum: 0.48720917984972706Best micro F1 model was saved at epoch 16! F1 sum best: 0.48778434439521634 at step 14; micro F1 best: 0.36871218439767595 at step 16 
Epoch: 17, train_loss: 3585.525128690735, val_loss: 5633.55283656468, micro F1: 0.35044800327456566, F1 sum: 0.4668136574482332Model was Not saved at epoch 17! F1 sum best: 0.48778434439521634 at step 14; micro F1 best: 0.36871218439767595 at step 16 
Epoch: 18, train_loss: 3526.7971820474427, val_loss: 6139.089102313544, micro F1: 0.2976570395975917, F1 sum: 0.37848512446095506Model was Not saved at epoch 18! F1 sum best: 0.48778434439521634 at step 14; micro F1 best: 0.36871218439767595 at step 16 
Epoch: 19, train_loss: 3446.3034609969495, val_loss: 5742.486917103331, micro F1: 0.34637188879908837, F1 sum: 0.4560770444335503Model was Not saved at epoch 19! F1 sum best: 0.48778434439521634 at step 14; micro F1 best: 0.36871218439767595 at step 16 
Epoch: 20, train_loss: 3375.6340773783922, val_loss: 5103.706926650678, micro F1: 0.40889989990294756, F1 sum: 0.5403480921546967Best F1 sum model was saved at epoch 20! F1 sum best: 0.5403480921546967 at step 20; micro F1 best: 0.36871218439767595 at step 16 
Best micro F1 model was saved at epoch 20! F1 sum best: 0.5403480921546967 at step 20; micro F1 best: 0.40889989990294756 at step 20 
Epoch: 21, train_loss: 3373.8304841029876, val_loss: 5530.939500895329, micro F1: 0.3671280364439705, F1 sum: 0.4892369455951969Model was Not saved at epoch 21! F1 sum best: 0.5403480921546967 at step 20; micro F1 best: 0.40889989990294756 at step 20 
Epoch: 22, train_loss: 3288.0671574552016, val_loss: 5898.869170535667, micro F1: 0.3206323510631288, F1 sum: 0.4244341313969736Model was Not saved at epoch 22! F1 sum best: 0.5403480921546967 at step 20; micro F1 best: 0.40889989990294756 at step 20 
Epoch: 23, train_loss: 3276.4715027908865, val_loss: 5285.384176143756, micro F1: 0.379548076357734, F1 sum: 0.4973644675051825Model was Not saved at epoch 23! F1 sum best: 0.5403480921546967 at step 20; micro F1 best: 0.40889989990294756 at step 20 
Epoch: 24, train_loss: 3195.3280301759437, val_loss: 5174.723632905322, micro F1: 0.4003938768272443, F1 sum: 0.5311566171569969Model was Not saved at epoch 24! F1 sum best: 0.5403480921546967 at step 20; micro F1 best: 0.40889989990294756 at step 20 
Epoch: 25, train_loss: 3160.1527394486616, val_loss: 5393.931911676191, micro F1: 0.39062547317977686, F1 sum: 0.517428664983739Model was Not saved at epoch 25! F1 sum best: 0.5403480921546967 at step 20; micro F1 best: 0.40889989990294756 at step 20 
Epoch: 26, train_loss: 3135.5366912307463, val_loss: 4987.814516838019, micro F1: 0.3996894553400731, F1 sum: 0.5361965304205114Model was Not saved at epoch 26! F1 sum best: 0.5403480921546967 at step 20; micro F1 best: 0.40889989990294756 at step 20 
Epoch: 27, train_loss: 3125.081529880224, val_loss: 4711.502008528138, micro F1: 0.440169790534613, F1 sum: 0.594834468662278Best F1 sum model was saved at epoch 27! F1 sum best: 0.594834468662278 at step 27; micro F1 best: 0.40889989990294756 at step 20 
Best micro F1 model was saved at epoch 27! F1 sum best: 0.594834468662278 at step 27; micro F1 best: 0.440169790534613 at step 27 
Epoch: 28, train_loss: 3074.115161424252, val_loss: 5347.997022715087, micro F1: 0.4296824630965906, F1 sum: 0.582156896477712Model was Not saved at epoch 28! F1 sum best: 0.594834468662278 at step 27; micro F1 best: 0.440169790534613 at step 27 
Epoch: 29, train_loss: 3000.3186960910652, val_loss: 5234.674913808703, micro F1: 0.44232754307334593, F1 sum: 0.6038458198547005Best F1 sum model was saved at epoch 29! F1 sum best: 0.6038458198547005 at step 29; micro F1 best: 0.440169790534613 at step 27 
Best micro F1 model was saved at epoch 29! F1 sum best: 0.6038458198547005 at step 29; micro F1 best: 0.44232754307334593 at step 29 
Epoch: 30, train_loss: 3004.4386109747975, val_loss: 5470.587135253784, micro F1: 0.39145933666665467, F1 sum: 0.5257980477904349Model was Not saved at epoch 30! F1 sum best: 0.6038458198547005 at step 29; micro F1 best: 0.44232754307334593 at step 29 
Epoch: 31, train_loss: 2953.9126849212735, val_loss: 5209.054920317915, micro F1: 0.35666753313153093, F1 sum: 0.4764520627909254Model was Not saved at epoch 31! F1 sum best: 0.6038458198547005 at step 29; micro F1 best: 0.44232754307334593 at step 29 
Epoch: 32, train_loss: 2970.4200309906646, val_loss: 5180.974367152278, micro F1: 0.3919591452307941, F1 sum: 0.5283374765705049Model was Not saved at epoch 32! F1 sum best: 0.6038458198547005 at step 29; micro F1 best: 0.44232754307334593 at step 29 
Epoch: 33, train_loss: 2927.554041940342, val_loss: 5151.704037950064, micro F1: 0.40882555741118265, F1 sum: 0.5532313620540663Model was Not saved at epoch 33! F1 sum best: 0.6038458198547005 at step 29; micro F1 best: 0.44232754307334593 at step 29 
Epoch: 34, train_loss: 2912.7688285986405, val_loss: 6138.2226915641995, micro F1: 0.33836340428242695, F1 sum: 0.45345910222625513Model was Not saved at epoch 34! F1 sum best: 0.6038458198547005 at step 29; micro F1 best: 0.44232754307334593 at step 29 
Epoch: 35, train_loss: 2874.38552259421, val_loss: 5166.010229537885, micro F1: 0.42022267804835184, F1 sum: 0.5608471879436213Model was Not saved at epoch 35! F1 sum best: 0.6038458198547005 at step 29; micro F1 best: 0.44232754307334593 at step 29 
Epoch: 36, train_loss: 2884.908948145644, val_loss: 5189.561222214252, micro F1: 0.3608509142560555, F1 sum: 0.483256831019249Model was Not saved at epoch 36! F1 sum best: 0.6038458198547005 at step 29; micro F1 best: 0.44232754307334593 at step 29 
Epoch: 37, train_loss: 2823.905022049532, val_loss: 5049.175388606575, micro F1: 0.45123197015273037, F1 sum: 0.625054161057498Best F1 sum model was saved at epoch 37! F1 sum best: 0.625054161057498 at step 37; micro F1 best: 0.44232754307334593 at step 29 
Best micro F1 model was saved at epoch 37! F1 sum best: 0.625054161057498 at step 37; micro F1 best: 0.45123197015273037 at step 37 
Epoch: 38, train_loss: 2817.8359703813135, val_loss: 5612.11222957354, micro F1: 0.40530140889362276, F1 sum: 0.5412965489643586Model was Not saved at epoch 38! F1 sum best: 0.625054161057498 at step 37; micro F1 best: 0.45123197015273037 at step 37 
Epoch: 39, train_loss: 2827.1495041033145, val_loss: 4750.327988682936, micro F1: 0.47745446095808197, F1 sum: 0.6623314399846361Best F1 sum model was saved at epoch 39! F1 sum best: 0.6623314399846361 at step 39; micro F1 best: 0.45123197015273037 at step 37 
Best micro F1 model was saved at epoch 39! F1 sum best: 0.6623314399846361 at step 39; micro F1 best: 0.47745446095808197 at step 39 
Epoch: 40, train_loss: 2749.8051334442457, val_loss: 5661.086800973862, micro F1: 0.4216501361457631, F1 sum: 0.5654962786863962Model was Not saved at epoch 40! F1 sum best: 0.6623314399846361 at step 39; micro F1 best: 0.47745446095808197 at step 39 
Epoch: 41, train_loss: 2727.9430815718174, val_loss: 5780.231674434617, micro F1: 0.373910835631735, F1 sum: 0.504509337801331Model was Not saved at epoch 41! F1 sum best: 0.6623314399846361 at step 39; micro F1 best: 0.47745446095808197 at step 39 
Epoch: 42, train_loss: 2771.2947934017943, val_loss: 4468.74444198329, micro F1: 0.44274389442483275, F1 sum: 0.5996606359700308Model was Not saved at epoch 42! F1 sum best: 0.6623314399846361 at step 39; micro F1 best: 0.47745446095808197 at step 39 
Epoch: 43, train_loss: 2743.4521261408886, val_loss: 6182.113706599921, micro F1: 0.35897644480410235, F1 sum: 0.48181612584272293Model was Not saved at epoch 43! F1 sum best: 0.6623314399846361 at step 39; micro F1 best: 0.47745446095808197 at step 39 
Epoch: 44, train_loss: 2717.6692675209465, val_loss: 5021.765722776763, micro F1: 0.3933297847795378, F1 sum: 0.5254098732579071Model was Not saved at epoch 44! F1 sum best: 0.6623314399846361 at step 39; micro F1 best: 0.47745446095808197 at step 39 
Epoch: 45, train_loss: 2691.8071357503627, val_loss: 5455.21717693191, micro F1: 0.39479851779178715, F1 sum: 0.5311550378975577Model was Not saved at epoch 45! F1 sum best: 0.6623314399846361 at step 39; micro F1 best: 0.47745446095808197 at step 39 
Epoch: 46, train_loss: 2676.860831415374, val_loss: 4803.63220286866, micro F1: 0.4858179495893031, F1 sum: 0.6679762553903856Best F1 sum model was saved at epoch 46! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.47745446095808197 at step 39 
Best micro F1 model was saved at epoch 46! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 47, train_loss: 2666.807687652766, val_loss: 5594.443997445827, micro F1: 0.38629829515703024, F1 sum: 0.5190210344224397Model was Not saved at epoch 47! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 48, train_loss: 2613.6301898193415, val_loss: 5698.713741730899, micro F1: 0.38288955120854856, F1 sum: 0.5224256098550237Model was Not saved at epoch 48! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 49, train_loss: 2624.754902114575, val_loss: 4976.240871474147, micro F1: 0.4330310650585488, F1 sum: 0.5902060113730082Model was Not saved at epoch 49! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 50, train_loss: 2647.86315485919, val_loss: 5822.904707553486, micro F1: 0.3799714467454275, F1 sum: 0.5151715268455822Model was Not saved at epoch 50! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 51, train_loss: 2600.3647285472243, val_loss: 5135.5486968532205, micro F1: 0.45772449416266076, F1 sum: 0.6286058899746119Model was Not saved at epoch 51! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 52, train_loss: 2607.2733530008727, val_loss: 5620.854658773169, micro F1: 0.37561471519826833, F1 sum: 0.5138874138416819Model was Not saved at epoch 52! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 53, train_loss: 2622.625659113032, val_loss: 4897.808399206649, micro F1: 0.43866224233643153, F1 sum: 0.6015194918548029Model was Not saved at epoch 53! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 54, train_loss: 2567.251286917946, val_loss: 5619.6410150732845, micro F1: 0.41834649786105726, F1 sum: 0.5748946128059742Model was Not saved at epoch 54! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 55, train_loss: 2595.050769212853, val_loss: 5407.469598964478, micro F1: 0.39606741067970386, F1 sum: 0.53150625648409Model was Not saved at epoch 55! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 56, train_loss: 2560.905594888612, val_loss: 5308.93710849341, micro F1: 0.40661802103192407, F1 sum: 0.5499310596905312Model was Not saved at epoch 56! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 57, train_loss: 2578.3470220429163, val_loss: 4919.972464752695, micro F1: 0.4536148949157602, F1 sum: 0.6274248382753285Model was Not saved at epoch 57! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 58, train_loss: 2533.568778487333, val_loss: 4861.511401250027, micro F1: 0.47333082056526715, F1 sum: 0.6602196120127701Model was Not saved at epoch 58! F1 sum best: 0.6679762553903856 at step 46; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 59, train_loss: 2541.3856496010753, val_loss: 4527.347863380176, micro F1: 0.48189253855671266, F1 sum: 0.6715485333593582Best F1 sum model was saved at epoch 59! F1 sum best: 0.6715485333593582 at step 59; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 60, train_loss: 2517.0399654487437, val_loss: 5283.29365925553, micro F1: 0.4076947701202395, F1 sum: 0.5512447882754108Model was Not saved at epoch 60! F1 sum best: 0.6715485333593582 at step 59; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 61, train_loss: 2489.173518985913, val_loss: 5258.037525539597, micro F1: 0.4470254299948768, F1 sum: 0.630661906664803Model was Not saved at epoch 61! F1 sum best: 0.6715485333593582 at step 59; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 62, train_loss: 2480.301957429889, val_loss: 4873.56020428706, micro F1: 0.48342460415078675, F1 sum: 0.6778243215523313Best F1 sum model was saved at epoch 62! F1 sum best: 0.6778243215523313 at step 62; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 63, train_loss: 2494.9479710983032, val_loss: 5026.540791926284, micro F1: 0.45986029290094543, F1 sum: 0.6318097447191727Model was Not saved at epoch 63! F1 sum best: 0.6778243215523313 at step 62; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 64, train_loss: 2513.949014133439, val_loss: 4951.66061911732, micro F1: 0.4440247186202517, F1 sum: 0.6082467362013024Model was Not saved at epoch 64! F1 sum best: 0.6778243215523313 at step 62; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 65, train_loss: 2471.2507941501135, val_loss: 4750.106938299723, micro F1: 0.47818016101033817, F1 sum: 0.6518634344856461Model was Not saved at epoch 65! F1 sum best: 0.6778243215523313 at step 62; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 66, train_loss: 2446.720937043157, val_loss: 5084.53461768416, micro F1: 0.4252091537210314, F1 sum: 0.5828245727059462Model was Not saved at epoch 66! F1 sum best: 0.6778243215523313 at step 62; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 67, train_loss: 2454.050422955147, val_loss: 5243.811411006996, micro F1: 0.4310873017180711, F1 sum: 0.5938678143016507Model was Not saved at epoch 67! F1 sum best: 0.6778243215523313 at step 62; micro F1 best: 0.4858179495893031 at step 46 
Epoch: 68, train_loss: 2454.6986196403896, val_loss: 4975.329340474369, micro F1: 0.4957948462061419, F1 sum: 0.6893472594060275Best F1 sum model was saved at epoch 68! F1 sum best: 0.6893472594060275 at step 68; micro F1 best: 0.4858179495893031 at step 46 
Best micro F1 model was saved at epoch 68! F1 sum best: 0.6893472594060275 at step 68; micro F1 best: 0.4957948462061419 at step 68 
Epoch: 69, train_loss: 2440.1603295821724, val_loss: 5476.180049202715, micro F1: 0.41737856902958204, F1 sum: 0.568568048068361Model was Not saved at epoch 69! F1 sum best: 0.6893472594060275 at step 68; micro F1 best: 0.4957948462061419 at step 68 
Epoch: 70, train_loss: 2441.149317848673, val_loss: 4853.53451105766, micro F1: 0.4617621122810912, F1 sum: 0.6336712574564293Model was Not saved at epoch 70! F1 sum best: 0.6893472594060275 at step 68; micro F1 best: 0.4957948462061419 at step 68 
Epoch: 71, train_loss: 2416.2042343420017, val_loss: 5018.977865305108, micro F1: 0.4627987857534511, F1 sum: 0.6322130468883794Model was Not saved at epoch 71! F1 sum best: 0.6893472594060275 at step 68; micro F1 best: 0.4957948462061419 at step 68 
Epoch: 72, train_loss: 2430.793901872479, val_loss: 4976.985590377201, micro F1: 0.5100132055125831, F1 sum: 0.7165416546079845Best F1 sum model was saved at epoch 72! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.4957948462061419 at step 68 
Best micro F1 model was saved at epoch 72! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 73, train_loss: 2404.4346895059844, val_loss: 4959.942120282601, micro F1: 0.45742227390758977, F1 sum: 0.6310658622463886Model was Not saved at epoch 73! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 74, train_loss: 2411.59206472551, val_loss: 5106.773361524877, micro F1: 0.48441673831548543, F1 sum: 0.6787039645379991Model was Not saved at epoch 74! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 75, train_loss: 2415.131081172411, val_loss: 5145.62351066464, micro F1: 0.4415336814961241, F1 sum: 0.6102275998853051Model was Not saved at epoch 75! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 76, train_loss: 2399.12990711393, val_loss: 5696.085534291342, micro F1: 0.41519888122177995, F1 sum: 0.5609915376679662Model was Not saved at epoch 76! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 77, train_loss: 2371.972867519557, val_loss: 5004.085616674274, micro F1: 0.436493621232997, F1 sum: 0.5931261919760193Model was Not saved at epoch 77! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 78, train_loss: 2405.4140943453235, val_loss: 4761.949185243187, micro F1: 0.46719381617767797, F1 sum: 0.6391860195068451Model was Not saved at epoch 78! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 79, train_loss: 2354.5044116863473, val_loss: 5554.9869913375005, micro F1: 0.40446038177469745, F1 sum: 0.5539918266579965Model was Not saved at epoch 79! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 80, train_loss: 2364.5998562680334, val_loss: 5149.448354107638, micro F1: 0.44030907105407097, F1 sum: 0.6012961279911906Model was Not saved at epoch 80! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 81, train_loss: 2352.1344232968418, val_loss: 4671.540272926602, micro F1: 0.49317289878533, F1 sum: 0.6891333862605128Model was Not saved at epoch 81! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 82, train_loss: 2346.0418600769876, val_loss: 5150.1259331901865, micro F1: 0.4610181157486901, F1 sum: 0.6361415921768032Model was Not saved at epoch 82! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 83, train_loss: 2372.181919631361, val_loss: 5494.135715804684, micro F1: 0.43590331503316215, F1 sum: 0.6047333831696353Model was Not saved at epoch 83! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 84, train_loss: 2327.204410795022, val_loss: 5434.202245281388, micro F1: 0.44212934229290113, F1 sum: 0.6092880733654359Model was Not saved at epoch 84! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 85, train_loss: 2350.5206749210683, val_loss: 4594.865754091491, micro F1: 0.5072071724678001, F1 sum: 0.7115463440745466Model was Not saved at epoch 85! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 86, train_loss: 2316.7070746115032, val_loss: 4861.8630845642965, micro F1: 0.4826104252878091, F1 sum: 0.667273224079751Model was Not saved at epoch 86! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 87, train_loss: 2289.483600522775, val_loss: 5782.859908843723, micro F1: 0.3940513358475679, F1 sum: 0.550399856647103Model was Not saved at epoch 87! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 88, train_loss: 2305.928667563714, val_loss: 4501.897425895247, micro F1: 0.500870379023642, F1 sum: 0.6898155168664137Model was Not saved at epoch 88! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 89, train_loss: 2286.939735839372, val_loss: 5085.136440272133, micro F1: 0.4984026036807336, F1 sum: 0.7018264836515338Model was Not saved at epoch 89! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 90, train_loss: 2306.309402921113, val_loss: 5625.267781045598, micro F1: 0.4949295486779495, F1 sum: 0.686279267989524Model was Not saved at epoch 90! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 91, train_loss: 2285.6784144091266, val_loss: 4805.388109719691, micro F1: 0.4835821854076736, F1 sum: 0.6708399125160819Model was Not saved at epoch 91! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 92, train_loss: 2288.3321420643506, val_loss: 4779.8200508502005, micro F1: 0.49509164656871385, F1 sum: 0.6846203285240335Model was Not saved at epoch 92! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 93, train_loss: 2271.9079863476077, val_loss: 5603.057451856633, micro F1: 0.4531095864479236, F1 sum: 0.6275974299789747Model was Not saved at epoch 93! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 94, train_loss: 2273.01765748186, val_loss: 6118.846914808576, micro F1: 0.3942644248253449, F1 sum: 0.5337965346554332Model was Not saved at epoch 94! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 95, train_loss: 2283.394950577323, val_loss: 4754.288468199472, micro F1: 0.48596591141298023, F1 sum: 0.6750977701930727Model was Not saved at epoch 95! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 96, train_loss: 2254.2608127155536, val_loss: 4522.483500962457, micro F1: 0.5003332959711163, F1 sum: 0.6980575590733982Model was Not saved at epoch 96! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 97, train_loss: 2276.317079086664, val_loss: 4591.119889713203, micro F1: 0.5083654954117568, F1 sum: 0.7100416745975964Model was Not saved at epoch 97! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 98, train_loss: 2250.2088864384305, val_loss: 4747.815058023359, micro F1: 0.4773833422300716, F1 sum: 0.6589545031441655Model was Not saved at epoch 98! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 99, train_loss: 2252.912339679322, val_loss: 5055.134764600855, micro F1: 0.4651677627014578, F1 sum: 0.6529345412352086Model was Not saved at epoch 99! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 100, train_loss: 2264.758204264972, val_loss: 4970.730486869191, micro F1: 0.49347239833441564, F1 sum: 0.6914430539592407Model was Not saved at epoch 100! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 101, train_loss: 2277.7920741353432, val_loss: 4891.37549768202, micro F1: 0.4871238632011227, F1 sum: 0.6841923906213196Model was Not saved at epoch 101! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 102, train_loss: 2254.4059496630957, val_loss: 4996.594254819986, micro F1: 0.4728815526992548, F1 sum: 0.6550024655580273Model was Not saved at epoch 102! F1 sum best: 0.7165416546079845 at step 72; micro F1 best: 0.5100132055125831 at step 72 
Epoch: 103, train_loss: 2235.1583323522823, val_loss: 4618.016101885587, micro F1: 0.5142178468425603, F1 sum: 0.7242509333849739Best F1 sum model was saved at epoch 103! F1 sum best: 0.7242509333849739 at step 103; micro F1 best: 0.5100132055125831 at step 72 
Best micro F1 model was saved at epoch 103! F1 sum best: 0.7242509333849739 at step 103; micro F1 best: 0.5142178468425603 at step 103 
Epoch: 104, train_loss: 2215.404557041571, val_loss: 6248.799736883181, micro F1: 0.38696257534017303, F1 sum: 0.5246149416458441Model was Not saved at epoch 104! F1 sum best: 0.7242509333849739 at step 103; micro F1 best: 0.5142178468425603 at step 103 
Epoch: 105, train_loss: 2233.245644591498, val_loss: 6042.043645478165, micro F1: 0.4059396020990486, F1 sum: 0.5551088097643515Model was Not saved at epoch 105! F1 sum best: 0.7242509333849739 at step 103; micro F1 best: 0.5142178468425603 at step 103 
Epoch: 106, train_loss: 2248.366433123111, val_loss: 5185.145016876049, micro F1: 0.505724531145097, F1 sum: 0.7098481259312392Model was Not saved at epoch 106! F1 sum best: 0.7242509333849739 at step 103; micro F1 best: 0.5142178468425603 at step 103 
Epoch: 107, train_loss: 2186.7368448887023, val_loss: 6853.534555993974, micro F1: 0.3835098071560424, F1 sum: 0.5238340525471851Model was Not saved at epoch 107! F1 sum best: 0.7242509333849739 at step 103; micro F1 best: 0.5142178468425603 at step 103 
Epoch: 108, train_loss: 2231.9752869708723, val_loss: 4995.216812045935, micro F1: 0.4768772393038186, F1 sum: 0.662825079059985Model was Not saved at epoch 108! F1 sum best: 0.7242509333849739 at step 103; micro F1 best: 0.5142178468425603 at step 103 
Epoch: 109, train_loss: 2214.0357068555118, val_loss: 4919.147669764546, micro F1: 0.5202089979987553, F1 sum: 0.7315076311452382Best F1 sum model was saved at epoch 109! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5142178468425603 at step 103 
Best micro F1 model was saved at epoch 109! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 110, train_loss: 2213.660092944772, val_loss: 5579.018964975451, micro F1: 0.45101026063008853, F1 sum: 0.6241556741243888Model was Not saved at epoch 110! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 111, train_loss: 2229.342170664524, val_loss: 4893.7689753559725, micro F1: 0.48084100952546577, F1 sum: 0.6602477693980442Model was Not saved at epoch 111! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 112, train_loss: 2180.765658313791, val_loss: 4989.906596213889, micro F1: 0.4820830490939746, F1 sum: 0.674888373281495Model was Not saved at epoch 112! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 113, train_loss: 2185.1832390174814, val_loss: 5319.101643011284, micro F1: 0.4708594279756653, F1 sum: 0.6519827184919753Model was Not saved at epoch 113! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 114, train_loss: 2188.8252890710146, val_loss: 4873.215189824501, micro F1: 0.48643968558559814, F1 sum: 0.6855394729459476Model was Not saved at epoch 114! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 115, train_loss: 2188.319198284414, val_loss: 4665.88060837239, micro F1: 0.5092095957811883, F1 sum: 0.7208905762458775Model was Not saved at epoch 115! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 116, train_loss: 2199.6376213317944, val_loss: 5327.505492799294, micro F1: 0.42867477743226723, F1 sum: 0.5861008801090065Model was Not saved at epoch 116! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 117, train_loss: 2198.178298401145, val_loss: 4781.420616200194, micro F1: 0.5011367709688784, F1 sum: 0.7099266120327836Model was Not saved at epoch 117! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 118, train_loss: 2163.0173748988473, val_loss: 4794.815062972096, micro F1: 0.4945441196983059, F1 sum: 0.6872906305794458Model was Not saved at epoch 118! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 119, train_loss: 2179.479782357192, val_loss: 4863.575491278122, micro F1: 0.47067523714134346, F1 sum: 0.6437680182226132Model was Not saved at epoch 119! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 120, train_loss: 2182.798282544118, val_loss: 4937.348264890413, micro F1: 0.47856638622924946, F1 sum: 0.6744737024329235Model was Not saved at epoch 120! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 121, train_loss: 2172.4754535133243, val_loss: 5175.916388980113, micro F1: 0.46464984131404585, F1 sum: 0.6525137598837849Model was Not saved at epoch 121! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 122, train_loss: 2161.23157499898, val_loss: 6360.257208580151, micro F1: 0.4121538710727312, F1 sum: 0.5720577696437696Model was Not saved at epoch 122! F1 sum best: 0.7315076311452382 at step 109; micro F1 best: 0.5202089979987553 at step 109 
Epoch: 123, train_loss: 2169.8908669562124, val_loss: 4570.968682722499, micro F1: 0.5238540901889792, F1 sum: 0.7440029475837037Best F1 sum model was saved at epoch 123! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5202089979987553 at step 109 
Best micro F1 model was saved at epoch 123! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 124, train_loss: 2162.83931527445, val_loss: 4650.518055229138, micro F1: 0.5158746068288261, F1 sum: 0.7226691927877255Model was Not saved at epoch 124! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 125, train_loss: 2145.124154355753, val_loss: 4728.985115458879, micro F1: 0.4967902483576533, F1 sum: 0.6918610290791056Model was Not saved at epoch 125! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 126, train_loss: 2151.7608709490937, val_loss: 4839.259841440556, micro F1: 0.4798269087220736, F1 sum: 0.6737490997700661Model was Not saved at epoch 126! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 127, train_loss: 2140.9532654934906, val_loss: 4948.799894773401, micro F1: 0.49387345594198756, F1 sum: 0.6910989121924407Model was Not saved at epoch 127! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 128, train_loss: 2175.1953909982863, val_loss: 5259.174478123896, micro F1: 0.46231928416964363, F1 sum: 0.6496724876823161Model was Not saved at epoch 128! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 129, train_loss: 2125.840267278228, val_loss: 5177.121932889956, micro F1: 0.5008039370460513, F1 sum: 0.701092457309096Model was Not saved at epoch 129! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 130, train_loss: 2139.966964761884, val_loss: 4766.108349237281, micro F1: 0.4832058146324319, F1 sum: 0.661012804348987Model was Not saved at epoch 130! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 131, train_loss: 2146.927868280865, val_loss: 4770.336177898571, micro F1: 0.5137527664211423, F1 sum: 0.7256757412091246Model was Not saved at epoch 131! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 132, train_loss: 2122.083532733096, val_loss: 5315.6805752466125, micro F1: 0.46691898117909053, F1 sum: 0.6490932854914717Model was Not saved at epoch 132! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 133, train_loss: 2137.7718835029605, val_loss: 4981.115321085478, micro F1: 0.5004926525458965, F1 sum: 0.6963530305200645Model was Not saved at epoch 133! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 134, train_loss: 2127.02933945044, val_loss: 5375.923742928232, micro F1: 0.4874751680690679, F1 sum: 0.6845212064514877Model was Not saved at epoch 134! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 135, train_loss: 2107.390460185093, val_loss: 5542.048885060164, micro F1: 0.46449172550589235, F1 sum: 0.640879237480082Model was Not saved at epoch 135! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 136, train_loss: 2120.076310103979, val_loss: 4648.234402993694, micro F1: 0.4977257434959029, F1 sum: 0.6892672130518274Model was Not saved at epoch 136! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 137, train_loss: 2110.1560439885725, val_loss: 5063.880514741565, micro F1: 0.4773261915892363, F1 sum: 0.6681686292873565Model was Not saved at epoch 137! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 138, train_loss: 2109.729840637194, val_loss: 5492.141996316302, micro F1: 0.4540532565132404, F1 sum: 0.6316975698625052Model was Not saved at epoch 138! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 139, train_loss: 2110.3364534505895, val_loss: 4858.028346206993, micro F1: 0.4938353980590667, F1 sum: 0.6941705288832357Model was Not saved at epoch 139! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 140, train_loss: 2112.2320163520326, val_loss: 4968.718545084508, micro F1: 0.48525454711634664, F1 sum: 0.6811361725488192Model was Not saved at epoch 140! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 141, train_loss: 2112.4385617036905, val_loss: 4702.844861894846, micro F1: 0.5069529176699386, F1 sum: 0.7113524243892243Model was Not saved at epoch 141! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 142, train_loss: 2097.0339741607568, val_loss: 6570.726981541762, micro F1: 0.4954208906847877, F1 sum: 0.7132091264372017Model was Not saved at epoch 142! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 143, train_loss: 2127.3689314452727, val_loss: 4500.9697806866225, micro F1: 0.5153240164353823, F1 sum: 0.7180826665722028Model was Not saved at epoch 143! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 144, train_loss: 2098.5597629783397, val_loss: 4783.974203746766, micro F1: 0.49927028561360204, F1 sum: 0.6978072303161753Model was Not saved at epoch 144! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 145, train_loss: 2103.6010336664654, val_loss: 4692.4824808957055, micro F1: 0.518148191908646, F1 sum: 0.7242764295713034Model was Not saved at epoch 145! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 146, train_loss: 2069.6013812918663, val_loss: 4973.859554738738, micro F1: 0.4943658769785543, F1 sum: 0.6958587802319622Model was Not saved at epoch 146! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 147, train_loss: 2073.186718257003, val_loss: 5349.661171203479, micro F1: 0.4595062502117798, F1 sum: 0.648890019365793Model was Not saved at epoch 147! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 148, train_loss: 2108.601151324386, val_loss: 6034.068693794931, micro F1: 0.46090225309702265, F1 sum: 0.6522193401387085Model was Not saved at epoch 148! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 149, train_loss: 2083.59288539587, val_loss: 6338.658965736006, micro F1: 0.43753839616356344, F1 sum: 0.6052814025007289Model was Not saved at epoch 149! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 150, train_loss: 2079.238185588653, val_loss: 5385.570201518324, micro F1: 0.4696906273496097, F1 sum: 0.6509198337694972Model was Not saved at epoch 150! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 151, train_loss: 2084.6998643814027, val_loss: 4740.14209350571, micro F1: 0.51156785103182, F1 sum: 0.7212369661222814Model was Not saved at epoch 151! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 152, train_loss: 2083.8205256155757, val_loss: 5065.362765453756, micro F1: 0.4909727130045212, F1 sum: 0.6869124049045998Model was Not saved at epoch 152! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 153, train_loss: 2060.48484856454, val_loss: 5291.54551467703, micro F1: 0.4714508536368764, F1 sum: 0.6590379874631254Model was Not saved at epoch 153! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 154, train_loss: 2069.184852941782, val_loss: 4708.325956792881, micro F1: 0.5212542992434465, F1 sum: 0.7392522391669142Model was Not saved at epoch 154! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 155, train_loss: 2084.402220104737, val_loss: 5262.601185240783, micro F1: 0.45535080604604444, F1 sum: 0.630428581182908Model was Not saved at epoch 155! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 156, train_loss: 2054.3133796208203, val_loss: 4803.494167087289, micro F1: 0.5071940254536458, F1 sum: 0.70714013219828Model was Not saved at epoch 156! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 157, train_loss: 2061.952602229018, val_loss: 5070.304947439581, micro F1: 0.5075390517362394, F1 sum: 0.71513467301592Model was Not saved at epoch 157! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 158, train_loss: 2055.5668073575866, val_loss: 5605.660596241554, micro F1: 0.46660762795496946, F1 sum: 0.6528729415594323Model was Not saved at epoch 158! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 159, train_loss: 2074.8023045174687, val_loss: 5666.730313290222, micro F1: 0.4602644335987861, F1 sum: 0.6524139939212545Model was Not saved at epoch 159! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 160, train_loss: 2056.5171766736844, val_loss: 5066.7968396252645, micro F1: 0.4661094154335539, F1 sum: 0.6443906529878707Model was Not saved at epoch 160! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 161, train_loss: 2044.8434015278394, val_loss: 5196.995456159736, micro F1: 0.45552138283483146, F1 sum: 0.6405947269860159Model was Not saved at epoch 161! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 162, train_loss: 2034.9177959978633, val_loss: 5240.399981848896, micro F1: 0.4912886806181632, F1 sum: 0.688428148883395Model was Not saved at epoch 162! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 163, train_loss: 2054.4787742108388, val_loss: 5034.462894351843, micro F1: 0.4967838422428031, F1 sum: 0.6961428360981547Model was Not saved at epoch 163! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 164, train_loss: 2049.781444053658, val_loss: 5266.368793672882, micro F1: 0.48440526397171196, F1 sum: 0.6808435325877022Model was Not saved at epoch 164! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 165, train_loss: 2093.5640740353647, val_loss: 5101.437247164237, micro F1: 0.5081062925943721, F1 sum: 0.721414474747083Model was Not saved at epoch 165! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 166, train_loss: 2016.7189213559006, val_loss: 5128.536102905248, micro F1: 0.49920172051740036, F1 sum: 0.7046000102491234Model was Not saved at epoch 166! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 167, train_loss: 2030.8709879300523, val_loss: 4933.777850625726, micro F1: 0.49836071679795474, F1 sum: 0.7107370190181125Model was Not saved at epoch 167! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 168, train_loss: 2048.129566802079, val_loss: 4829.813253018074, micro F1: 0.5054358002659379, F1 sum: 0.7041717148753377Model was Not saved at epoch 168! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 169, train_loss: 2029.0472078584032, val_loss: 4859.83806293613, micro F1: 0.518170584454856, F1 sum: 0.7413068558234954Model was Not saved at epoch 169! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 170, train_loss: 2050.42703962341, val_loss: 5434.84942560705, micro F1: 0.47122683775184365, F1 sum: 0.6594145057551941Model was Not saved at epoch 170! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 171, train_loss: 2027.7445085516879, val_loss: 5275.971588174191, micro F1: 0.4924556123640286, F1 sum: 0.6903115237076918Model was Not saved at epoch 171! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 172, train_loss: 2001.0342346775592, val_loss: 5798.716999512787, micro F1: 0.4251686710709085, F1 sum: 0.5759289062164801Model was Not saved at epoch 172! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 173, train_loss: 2024.0459187410322, val_loss: 4917.431116725008, micro F1: 0.4715624084502148, F1 sum: 0.6520207810661911Model was Not saved at epoch 173! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 174, train_loss: 2018.1390046616423, val_loss: 5353.941575546439, micro F1: 0.5122082406393019, F1 sum: 0.7266988937359807Model was Not saved at epoch 174! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 175, train_loss: 2030.387843091812, val_loss: 5890.870371367782, micro F1: 0.4121523905992338, F1 sum: 0.5646667419382689Model was Not saved at epoch 175! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 176, train_loss: 2002.823609985016, val_loss: 5783.2745408328865, micro F1: 0.48093338663262936, F1 sum: 0.6880222831322802Model was Not saved at epoch 176! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 177, train_loss: 2034.136562930464, val_loss: 6067.23994249478, micro F1: 0.4368567128665745, F1 sum: 0.604545582079542Model was Not saved at epoch 177! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 178, train_loss: 2038.4813250511065, val_loss: 5005.303866346367, micro F1: 0.5008210035855882, F1 sum: 0.7011228552250032Model was Not saved at epoch 178! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 179, train_loss: 2003.7433018818454, val_loss: 6119.504801075284, micro F1: 0.4127225289936177, F1 sum: 0.5617571898934935Model was Not saved at epoch 179! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 180, train_loss: 2026.8124111491447, val_loss: 4909.403107982749, micro F1: 0.5060422304823684, F1 sum: 0.7177606973127695Model was Not saved at epoch 180! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 181, train_loss: 2015.3237646534437, val_loss: 4996.819169609807, micro F1: 0.4810474078602662, F1 sum: 0.6740807091083297Model was Not saved at epoch 181! F1 sum best: 0.7440029475837037 at step 123; micro F1 best: 0.5238540901889792 at step 123 
Epoch: 182, train_loss: 2002.4644721240638, val_loss: 4661.528346672033, micro F1: 0.5309090318662736, F1 sum: 0.7532962562635173Best F1 sum model was saved at epoch 182! F1 sum best: 0.7532962562635173 at step 182; micro F1 best: 0.5238540901889792 at step 123 
Best micro F1 model was saved at epoch 182! F1 sum best: 0.7532962562635173 at step 182; micro F1 best: 0.5309090318662736 at step 182 
Epoch: 183, train_loss: 2017.6817292212565, val_loss: 5212.83678303007, micro F1: 0.48312781067409866, F1 sum: 0.6753279318038646Model was Not saved at epoch 183! F1 sum best: 0.7532962562635173 at step 182; micro F1 best: 0.5309090318662736 at step 182 
Epoch: 184, train_loss: 2000.2265386031513, val_loss: 5003.414571207638, micro F1: 0.4910970426669034, F1 sum: 0.6887920811156316Model was Not saved at epoch 184! F1 sum best: 0.7532962562635173 at step 182; micro F1 best: 0.5309090318662736 at step 182 
Epoch: 185, train_loss: 2005.9895053792982, val_loss: 5571.19759110113, micro F1: 0.4686479821219109, F1 sum: 0.6615736185846496Model was Not saved at epoch 185! F1 sum best: 0.7532962562635173 at step 182; micro F1 best: 0.5309090318662736 at step 182 
Epoch: 186, train_loss: 1995.2852622663663, val_loss: 5150.286100300339, micro F1: 0.500159426254686, F1 sum: 0.7028532635761319Model was Not saved at epoch 186! F1 sum best: 0.7532962562635173 at step 182; micro F1 best: 0.5309090318662736 at step 182 
Epoch: 187, train_loss: 1991.4754145869458, val_loss: 4986.873398496148, micro F1: 0.5323088431362218, F1 sum: 0.7623373613972945Best F1 sum model was saved at epoch 187! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5309090318662736 at step 182 
Best micro F1 model was saved at epoch 187! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 188, train_loss: 1985.274098619616, val_loss: 4794.399284680064, micro F1: 0.5114523774459182, F1 sum: 0.7223543456146218Model was Not saved at epoch 188! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 189, train_loss: 1999.445350919159, val_loss: 5185.518344515003, micro F1: 0.4832690546415203, F1 sum: 0.6743376775984264Model was Not saved at epoch 189! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 190, train_loss: 1993.199495470956, val_loss: 5830.189321325937, micro F1: 0.4427323670931704, F1 sum: 0.6060995201984042Model was Not saved at epoch 190! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 191, train_loss: 1992.5961905077033, val_loss: 5117.935451562516, micro F1: 0.478370268146197, F1 sum: 0.6729794986972896Model was Not saved at epoch 191! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 192, train_loss: 1975.2581128233787, val_loss: 5040.9081803324325, micro F1: 0.4941103979431015, F1 sum: 0.6916308863545662Model was Not saved at epoch 192! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 193, train_loss: 2004.5472237020897, val_loss: 5119.253269707163, micro F1: 0.5124535838413673, F1 sum: 0.7242639258815567Model was Not saved at epoch 193! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 194, train_loss: 1990.0863055393602, val_loss: 5385.675853661573, micro F1: 0.48151540530331355, F1 sum: 0.6814885437522511Model was Not saved at epoch 194! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 195, train_loss: 1996.8410224790057, val_loss: 4624.68400267729, micro F1: 0.5102936267959497, F1 sum: 0.7136472928913766Model was Not saved at epoch 195! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 196, train_loss: 1994.9287208546039, val_loss: 6437.493698613253, micro F1: 0.4311934370092482, F1 sum: 0.5913598347375341Model was Not saved at epoch 196! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 197, train_loss: 1984.3255900595423, val_loss: 5110.372737011251, micro F1: 0.4961132180974043, F1 sum: 0.6972178156912074Model was Not saved at epoch 197! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 198, train_loss: 1948.0737839154085, val_loss: 5964.507545965414, micro F1: 0.4227391881349225, F1 sum: 0.5800951996168048Model was Not saved at epoch 198! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 199, train_loss: 1995.6952114029234, val_loss: 4934.926751108529, micro F1: 0.5066739533261474, F1 sum: 0.7129622931811659Model was Not saved at epoch 199! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 200, train_loss: 1980.5008076183337, val_loss: 5125.179936488469, micro F1: 0.48862615464022385, F1 sum: 0.6897276652724638Model was Not saved at epoch 200! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 201, train_loss: 1880.7741377288578, val_loss: 5010.092688996035, micro F1: 0.51010286675737, F1 sum: 0.7219359742093123Model was Not saved at epoch 201! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 202, train_loss: 1879.6694979566341, val_loss: 4796.573918429203, micro F1: 0.522119014741232, F1 sum: 0.7309232235425346Model was Not saved at epoch 202! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 203, train_loss: 1882.4807737647827, val_loss: 5072.544509506163, micro F1: 0.5141311436844869, F1 sum: 0.7312894789783059Model was Not saved at epoch 203! F1 sum best: 0.7623373613972945 at step 187; micro F1 best: 0.5323088431362218 at step 187 
Epoch: 204, train_loss: 1851.7941614038448, val_loss: 5091.044884757139, micro F1: 0.5451191925199207, F1 sum: 0.7851450807653104Best F1 sum model was saved at epoch 204! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5323088431362218 at step 187 
Best micro F1 model was saved at epoch 204! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 205, train_loss: 1851.260212063402, val_loss: 5153.322331995393, micro F1: 0.5154379485039196, F1 sum: 0.7252121960361061Model was Not saved at epoch 205! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 206, train_loss: 1835.9885996554096, val_loss: 5261.405338533223, micro F1: 0.508332569959263, F1 sum: 0.7226428905434052Model was Not saved at epoch 206! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 207, train_loss: 1845.845036363958, val_loss: 5287.7769093417255, micro F1: 0.48769623599995005, F1 sum: 0.6820005738047257Model was Not saved at epoch 207! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 208, train_loss: 1860.5018705862667, val_loss: 4897.525895309324, micro F1: 0.5282806733075025, F1 sum: 0.7463748559561585Model was Not saved at epoch 208! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 209, train_loss: 1831.3393650029757, val_loss: 5614.360224863049, micro F1: 0.45444956549908966, F1 sum: 0.6261221247664556Model was Not saved at epoch 209! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 210, train_loss: 1836.6132218141404, val_loss: 5026.911784855959, micro F1: 0.5339340674814593, F1 sum: 0.7624986258005568Model was Not saved at epoch 210! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 211, train_loss: 1862.336238268143, val_loss: 5667.384032858536, micro F1: 0.4703497047452402, F1 sum: 0.6556164143608536Model was Not saved at epoch 211! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 212, train_loss: 1847.014585965224, val_loss: 5097.8288137897225, micro F1: 0.5273134329683671, F1 sum: 0.7532441410847847Model was Not saved at epoch 212! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 213, train_loss: 1823.977085157206, val_loss: 4805.003231934582, micro F1: 0.5265474232041015, F1 sum: 0.7470723033020514Model was Not saved at epoch 213! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 214, train_loss: 1848.228667188118, val_loss: 5340.636607531148, micro F1: 0.5141255615392463, F1 sum: 0.7254734783447324Model was Not saved at epoch 214! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 215, train_loss: 1846.273454161614, val_loss: 5067.389202886261, micro F1: 0.5409181707766645, F1 sum: 0.7743229755692786Model was Not saved at epoch 215! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 216, train_loss: 1834.520872026952, val_loss: 5800.589443339656, micro F1: 0.45181443364320634, F1 sum: 0.6256670268289478Model was Not saved at epoch 216! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 217, train_loss: 1830.5374804871926, val_loss: 5104.68989610672, micro F1: 0.4955150471883826, F1 sum: 0.6927603263660178Model was Not saved at epoch 217! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 218, train_loss: 1838.2829287786608, val_loss: 5404.787525573435, micro F1: 0.4823620824735372, F1 sum: 0.6773678887154195Model was Not saved at epoch 218! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 219, train_loss: 1824.6632287809664, val_loss: 4941.685171603846, micro F1: 0.5092325232128739, F1 sum: 0.7167808963125177Model was Not saved at epoch 219! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 220, train_loss: 1843.942591044393, val_loss: 4926.850749179721, micro F1: 0.523042874665892, F1 sum: 0.7384811671717519Model was Not saved at epoch 220! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 221, train_loss: 1818.4522785819245, val_loss: 5300.408329543036, micro F1: 0.49011764727480717, F1 sum: 0.6955651640206895Model was Not saved at epoch 221! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 222, train_loss: 1821.367544475323, val_loss: 6366.881950525567, micro F1: 0.44663826442944504, F1 sum: 0.6214923220096655Model was Not saved at epoch 222! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 223, train_loss: 1825.822778479661, val_loss: 5593.09609932825, micro F1: 0.4904144782871299, F1 sum: 0.6894287526987379Model was Not saved at epoch 223! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 224, train_loss: 1822.249894512765, val_loss: 5395.08387989675, micro F1: 0.49005691114853106, F1 sum: 0.6837520685489722Model was Not saved at epoch 224! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 225, train_loss: 1836.1486285203493, val_loss: 5563.256013556384, micro F1: 0.4734348764255022, F1 sum: 0.6608533083793493Model was Not saved at epoch 225! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 226, train_loss: 1810.2831614185022, val_loss: 6487.796939521408, micro F1: 0.4298690373824987, F1 sum: 0.5878925991955233Model was Not saved at epoch 226! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 227, train_loss: 1819.396289901862, val_loss: 5025.50962594493, micro F1: 0.5252587062389164, F1 sum: 0.7405768393470681Model was Not saved at epoch 227! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 228, train_loss: 1802.1745131423388, val_loss: 5095.834807143547, micro F1: 0.5041601074583013, F1 sum: 0.7106087747127275Model was Not saved at epoch 228! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 229, train_loss: 1816.711804654592, val_loss: 5063.866989221424, micro F1: 0.5181925843403709, F1 sum: 0.7352010478212605Model was Not saved at epoch 229! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 230, train_loss: 1805.3135580853746, val_loss: 5124.555149814114, micro F1: 0.5255469413027943, F1 sum: 0.7401033379794777Model was Not saved at epoch 230! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 231, train_loss: 1822.6198346741419, val_loss: 5767.54907980406, micro F1: 0.4526483149459333, F1 sum: 0.6309315127694693Model was Not saved at epoch 231! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 232, train_loss: 1816.1905316651146, val_loss: 5012.154764262959, micro F1: 0.5237208928107672, F1 sum: 0.7465103847464585Model was Not saved at epoch 232! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 233, train_loss: 1840.5839678969935, val_loss: 5185.804992215708, micro F1: 0.5257652183761821, F1 sum: 0.7449989368736473Model was Not saved at epoch 233! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 234, train_loss: 1792.8051130233227, val_loss: 5463.123815134168, micro F1: 0.4937543327253176, F1 sum: 0.6936287526233343Model was Not saved at epoch 234! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 235, train_loss: 1819.8676362046622, val_loss: 5165.0070294272155, micro F1: 0.4973754045148477, F1 sum: 0.6991559540382393Model was Not saved at epoch 235! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 236, train_loss: 1805.9211470638486, val_loss: 5997.124839341268, micro F1: 0.45376345931899775, F1 sum: 0.6314494507901638Model was Not saved at epoch 236! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 237, train_loss: 1801.9631673015485, val_loss: 4854.623936892797, micro F1: 0.5299886245576393, F1 sum: 0.7574878449802781Model was Not saved at epoch 237! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 238, train_loss: 1797.2916442999874, val_loss: 6023.34456363072, micro F1: 0.45190940844040595, F1 sum: 0.6178944025904154Model was Not saved at epoch 238! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 239, train_loss: 1812.903182119281, val_loss: 5114.672642278795, micro F1: 0.5031555594396195, F1 sum: 0.7062587524002386Model was Not saved at epoch 239! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 240, train_loss: 1816.974632856475, val_loss: 6305.78953307122, micro F1: 0.4390446036860036, F1 sum: 0.6113316518094507Model was Not saved at epoch 240! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 241, train_loss: 1791.6931770984136, val_loss: 5790.111687189589, micro F1: 0.46449067756766454, F1 sum: 0.6382016425641874Model was Not saved at epoch 241! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 242, train_loss: 1808.709192109758, val_loss: 5625.05254696589, micro F1: 0.4887206411241399, F1 sum: 0.6800925714434318Model was Not saved at epoch 242! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 243, train_loss: 1799.7920862883432, val_loss: 5374.2383973440155, micro F1: 0.48092288857127036, F1 sum: 0.6735310578261761Model was Not saved at epoch 243! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 244, train_loss: 1797.2300084197673, val_loss: 5185.277823281164, micro F1: 0.5380094240118827, F1 sum: 0.7715975125964785Model was Not saved at epoch 244! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 245, train_loss: 1800.30473263404, val_loss: 5137.723140457335, micro F1: 0.5072775528138057, F1 sum: 0.7100814349086022Model was Not saved at epoch 245! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 246, train_loss: 1807.1454981808263, val_loss: 4846.35790460743, micro F1: 0.5293193077949885, F1 sum: 0.7550223532051556Model was Not saved at epoch 246! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 247, train_loss: 1802.8278142761505, val_loss: 5327.916291619961, micro F1: 0.5133660223333815, F1 sum: 0.7337523324893481Model was Not saved at epoch 247! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 248, train_loss: 1812.841414244511, val_loss: 5291.469772831381, micro F1: 0.48523897734688337, F1 sum: 0.6824715687042499Model was Not saved at epoch 248! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 249, train_loss: 1788.1475125616105, val_loss: 5678.458664915524, micro F1: 0.4580677881943605, F1 sum: 0.6351211661004224Model was Not saved at epoch 249! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 250, train_loss: 1805.1461127167504, val_loss: 4941.506395116448, micro F1: 0.5412407327336647, F1 sum: 0.7720424296897059Model was Not saved at epoch 250! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 251, train_loss: 1814.5202964156135, val_loss: 5436.529939761385, micro F1: 0.48684740947313304, F1 sum: 0.6797341628998348Model was Not saved at epoch 251! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 252, train_loss: 1787.50713109042, val_loss: 5438.971251909, micro F1: 0.5303034579080607, F1 sum: 0.7602669312652021Model was Not saved at epoch 252! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 253, train_loss: 1800.985858470832, val_loss: 5053.018999751657, micro F1: 0.5049832317531885, F1 sum: 0.7092400809401624Model was Not saved at epoch 253! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 254, train_loss: 1807.1665856639283, val_loss: 5362.119802157395, micro F1: 0.4936765763093111, F1 sum: 0.6908810112455663Model was Not saved at epoch 254! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 255, train_loss: 1789.887212660072, val_loss: 4966.433960168312, micro F1: 0.5081001502355017, F1 sum: 0.7182069481396562Model was Not saved at epoch 255! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 256, train_loss: 1794.2041684805586, val_loss: 4908.58048996112, micro F1: 0.5351247112749358, F1 sum: 0.7618604924299386Model was Not saved at epoch 256! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 257, train_loss: 1795.6927450759345, val_loss: 5803.020389478964, micro F1: 0.522043036017567, F1 sum: 0.751370337408783Model was Not saved at epoch 257! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 258, train_loss: 1789.328029495341, val_loss: 5159.501397089723, micro F1: 0.4999633986755119, F1 sum: 0.7021825574794396Model was Not saved at epoch 258! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 259, train_loss: 1777.0282682201737, val_loss: 5457.971336436458, micro F1: 0.4889202574064863, F1 sum: 0.6848957965770012Model was Not saved at epoch 259! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 260, train_loss: 1794.966389904646, val_loss: 5259.327200862269, micro F1: 0.5323760504019447, F1 sum: 0.7602477001194227Model was Not saved at epoch 260! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 261, train_loss: 1778.1572048893024, val_loss: 5200.2260348914815, micro F1: 0.5155441385063265, F1 sum: 0.7351906017095947Model was Not saved at epoch 261! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 262, train_loss: 1782.1165973963389, val_loss: 5370.301443811817, micro F1: 0.5216098631809776, F1 sum: 0.7434506930935944Model was Not saved at epoch 262! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 263, train_loss: 1778.0221485822326, val_loss: 7340.354373445734, micro F1: 0.41004935438904794, F1 sum: 0.5590945919365349Model was Not saved at epoch 263! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 264, train_loss: 1808.086021747776, val_loss: 5603.419591013032, micro F1: 0.48857151812214095, F1 sum: 0.6866824803891177Model was Not saved at epoch 264! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 265, train_loss: 1800.3917767374999, val_loss: 4957.162452046759, micro F1: 0.5234299919267262, F1 sum: 0.7385892181756086Model was Not saved at epoch 265! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 266, train_loss: 1767.1466675990982, val_loss: 5478.95579560039, micro F1: 0.5054597315134742, F1 sum: 0.7126061001704632Model was Not saved at epoch 266! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 267, train_loss: 1793.0250550538235, val_loss: 5229.61475867002, micro F1: 0.5079460185739056, F1 sum: 0.7140071689670245Model was Not saved at epoch 267! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 268, train_loss: 1784.0034638815036, val_loss: 5258.223314691956, micro F1: 0.5114965071092835, F1 sum: 0.7250584860904685Model was Not saved at epoch 268! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 269, train_loss: 1786.0794008803784, val_loss: 5771.082870972653, micro F1: 0.5274448020599569, F1 sum: 0.7627462750501157Model was Not saved at epoch 269! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 270, train_loss: 1774.7685702029362, val_loss: 5387.236703148422, micro F1: 0.5385131452341738, F1 sum: 0.7762714863860309Model was Not saved at epoch 270! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 271, train_loss: 1786.3682654315553, val_loss: 5322.37703659727, micro F1: 0.5360041187015667, F1 sum: 0.7691963394334985Model was Not saved at epoch 271! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 272, train_loss: 1776.714857996909, val_loss: 5350.195043138228, micro F1: 0.4940996397950888, F1 sum: 0.6954048008874679Model was Not saved at epoch 272! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 273, train_loss: 1771.0298680036422, val_loss: 5134.852246070901, micro F1: 0.5043536836703424, F1 sum: 0.7123150863593157Model was Not saved at epoch 273! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 274, train_loss: 1795.9999822092404, val_loss: 5389.557904757869, micro F1: 0.5008721979727853, F1 sum: 0.7009671114733769Model was Not saved at epoch 274! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 275, train_loss: 1771.1718375381242, val_loss: 5390.9245220711455, micro F1: 0.47592770554329034, F1 sum: 0.6588312738489094Model was Not saved at epoch 275! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 276, train_loss: 1774.0831385654346, val_loss: 6688.831409749886, micro F1: 0.5083512146313296, F1 sum: 0.7259103270478893Model was Not saved at epoch 276! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 277, train_loss: 1779.5339933086004, val_loss: 4725.921879483697, micro F1: 0.5349263385345694, F1 sum: 0.7602290397429897Model was Not saved at epoch 277! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 278, train_loss: 1771.6133913254378, val_loss: 5274.905893214357, micro F1: 0.4790589141242132, F1 sum: 0.6649568533816345Model was Not saved at epoch 278! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 279, train_loss: 1754.91308865842, val_loss: 5361.906057029652, micro F1: 0.5182502566312905, F1 sum: 0.7369412771283047Model was Not saved at epoch 279! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 280, train_loss: 1802.3406229398165, val_loss: 5139.11193178501, micro F1: 0.5404500358786511, F1 sum: 0.7713134282370447Model was Not saved at epoch 280! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 281, train_loss: 1775.0597157476511, val_loss: 5324.8124722934635, micro F1: 0.5120388362847734, F1 sum: 0.722947980641402Model was Not saved at epoch 281! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 282, train_loss: 1786.2806706682838, val_loss: 5162.391726238033, micro F1: 0.5159324266191107, F1 sum: 0.7346975308122637Model was Not saved at epoch 282! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 283, train_loss: 1787.2624561888454, val_loss: 4804.147623751001, micro F1: 0.5175339874903633, F1 sum: 0.7303123652489376Model was Not saved at epoch 283! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 284, train_loss: 1762.3151215876746, val_loss: 4939.184016742123, micro F1: 0.5374384620517958, F1 sum: 0.7649932793102986Model was Not saved at epoch 284! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 285, train_loss: 1787.624947573982, val_loss: 5334.268522565253, micro F1: 0.5269179089935127, F1 sum: 0.7505419577559982Model was Not saved at epoch 285! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 286, train_loss: 1776.5022493223466, val_loss: 5284.152770376143, micro F1: 0.5032680526417, F1 sum: 0.7095754353974939Model was Not saved at epoch 286! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 287, train_loss: 1785.9035211571024, val_loss: 5378.198678372428, micro F1: 0.4839162514645068, F1 sum: 0.6782691480284749Model was Not saved at epoch 287! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 288, train_loss: 1779.5417074988572, val_loss: 5621.2694075657055, micro F1: 0.5070517296184941, F1 sum: 0.7220958071086898Model was Not saved at epoch 288! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 289, train_loss: 1777.4377996198853, val_loss: 5309.716677875258, micro F1: 0.5060522950315014, F1 sum: 0.7196498600588105Model was Not saved at epoch 289! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 290, train_loss: 1773.0734188210713, val_loss: 5257.617792619082, micro F1: 0.5163884225689496, F1 sum: 0.7300864922315062Model was Not saved at epoch 290! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 291, train_loss: 1782.2679454746851, val_loss: 5033.025848873271, micro F1: 0.5208647346153157, F1 sum: 0.7354449415596416Model was Not saved at epoch 291! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 292, train_loss: 1784.217149896312, val_loss: 6909.017832949757, micro F1: 0.4233093833617962, F1 sum: 0.5806712180774326Model was Not saved at epoch 292! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 293, train_loss: 1749.9945425464296, val_loss: 5092.254870493586, micro F1: 0.5416158438766918, F1 sum: 0.7758253369791418Model was Not saved at epoch 293! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 294, train_loss: 1770.1457444591003, val_loss: 5744.256475009024, micro F1: 0.5137744906402076, F1 sum: 0.7391674972016213Model was Not saved at epoch 294! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 295, train_loss: 1758.1852814843833, val_loss: 5346.742147424568, micro F1: 0.4856834133679513, F1 sum: 0.6797031127868346Model was Not saved at epoch 295! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 296, train_loss: 1741.5614048504735, val_loss: 5400.247156115559, micro F1: 0.4707549305552675, F1 sum: 0.658249712094342Model was Not saved at epoch 296! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 297, train_loss: 1763.70969135952, val_loss: 5413.3507956673075, micro F1: 0.4919740333343119, F1 sum: 0.6957062788238848Model was Not saved at epoch 297! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 298, train_loss: 1762.9489182223645, val_loss: 5552.635605369384, micro F1: 0.48818609872444846, F1 sum: 0.6885203733753922Model was Not saved at epoch 298! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 299, train_loss: 1760.1769071830572, val_loss: 5584.824640536681, micro F1: 0.5002725172262823, F1 sum: 0.7066094433629284Model was Not saved at epoch 299! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 300, train_loss: 1763.7324113576078, val_loss: 5243.668457842432, micro F1: 0.5035604088989203, F1 sum: 0.7095520398671094Model was Not saved at epoch 300! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 301, train_loss: 1767.1377055568817, val_loss: 5460.839771355192, micro F1: 0.5094403387648829, F1 sum: 0.726196661462139Model was Not saved at epoch 301! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 302, train_loss: 1762.5381450558561, val_loss: 6207.03101856634, micro F1: 0.4436404514291098, F1 sum: 0.619596071648228Model was Not saved at epoch 302! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 303, train_loss: 1733.717327104654, val_loss: 5195.550674300951, micro F1: 0.5282055882290781, F1 sum: 0.752137933381285Model was Not saved at epoch 303! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 304, train_loss: 1763.1643260092876, val_loss: 6395.823133643716, micro F1: 0.44181102505596453, F1 sum: 0.608957942324029Model was Not saved at epoch 304! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 305, train_loss: 1745.5735185891442, val_loss: 5179.538526572287, micro F1: 0.5140228300080101, F1 sum: 0.7292375468489051Model was Not saved at epoch 305! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 306, train_loss: 1754.2549083299996, val_loss: 5694.350360621078, micro F1: 0.46999191945142227, F1 sum: 0.6587326976433208Model was Not saved at epoch 306! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 307, train_loss: 1753.0214357718305, val_loss: 4882.8165603724, micro F1: 0.5422559006296069, F1 sum: 0.7776298381436694Model was Not saved at epoch 307! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 308, train_loss: 1774.7921596486935, val_loss: 5244.650414097123, micro F1: 0.5418412575646168, F1 sum: 0.7762013948278763Model was Not saved at epoch 308! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 309, train_loss: 1744.864493210951, val_loss: 5177.317873458378, micro F1: 0.5090990165020534, F1 sum: 0.7208958915482678Model was Not saved at epoch 309! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 310, train_loss: 1756.6981360042757, val_loss: 5077.44496067365, micro F1: 0.5314365500991698, F1 sum: 0.7577984831426874Model was Not saved at epoch 310! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 311, train_loss: 1770.9952751342494, val_loss: 5440.102114807814, micro F1: 0.49384679171877605, F1 sum: 0.6973481284774607Model was Not saved at epoch 311! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 312, train_loss: 1756.0998596056932, val_loss: 6447.557221787672, micro F1: 0.5177165601682039, F1 sum: 0.7458125932468496Model was Not saved at epoch 312! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 313, train_loss: 1766.690333669646, val_loss: 5133.707082325903, micro F1: 0.5205249730536404, F1 sum: 0.7400303487993369Model was Not saved at epoch 313! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 314, train_loss: 1765.2735210329954, val_loss: 5795.1010792749, micro F1: 0.4808133120843801, F1 sum: 0.6760718742880727Model was Not saved at epoch 314! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 315, train_loss: 1757.5804208446973, val_loss: 5483.431097236462, micro F1: 0.48156065501680134, F1 sum: 0.6707884276955156Model was Not saved at epoch 315! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 316, train_loss: 1750.9452657909399, val_loss: 5282.0036744621275, micro F1: 0.5274284462730672, F1 sum: 0.7511911781294657Model was Not saved at epoch 316! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 317, train_loss: 1761.6966938785304, val_loss: 5864.789300054932, micro F1: 0.4781126063215197, F1 sum: 0.6680496368385017Model was Not saved at epoch 317! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 318, train_loss: 1769.714279433883, val_loss: 5060.274067800492, micro F1: 0.5104207813288667, F1 sum: 0.7230835143834762Model was Not saved at epoch 318! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 319, train_loss: 1749.8575224876652, val_loss: 4984.4348851668965, micro F1: 0.5179358433056526, F1 sum: 0.7313779523211451Model was Not saved at epoch 319! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 320, train_loss: 1751.4391505602173, val_loss: 5032.059632358141, micro F1: 0.5158148361588246, F1 sum: 0.7284227619399037Model was Not saved at epoch 320! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 321, train_loss: 1772.4830840020627, val_loss: 5362.007016277251, micro F1: 0.49905783576899315, F1 sum: 0.7033562314807417Model was Not saved at epoch 321! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 322, train_loss: 1754.096382490202, val_loss: 5363.523977575824, micro F1: 0.5367025483426308, F1 sum: 0.7759396050051994Model was Not saved at epoch 322! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 323, train_loss: 1723.360630806152, val_loss: 5392.639001559776, micro F1: 0.5089390791265032, F1 sum: 0.7158789676648438Model was Not saved at epoch 323! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 324, train_loss: 1746.7686532143746, val_loss: 5487.054663244635, micro F1: 0.5295681143422067, F1 sum: 0.7578916505347781Model was Not saved at epoch 324! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 325, train_loss: 1756.687474798898, val_loss: 4974.343552797412, micro F1: 0.5211436529386749, F1 sum: 0.7406153709209926Model was Not saved at epoch 325! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 326, train_loss: 1729.003981218561, val_loss: 5226.164672252101, micro F1: 0.521829009231927, F1 sum: 0.7434556512164515Model was Not saved at epoch 326! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 327, train_loss: 1766.3092476655838, val_loss: 5825.12282281338, micro F1: 0.47138153274184635, F1 sum: 0.6542155065418305Model was Not saved at epoch 327! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 328, train_loss: 1765.0766966190517, val_loss: 5125.305065691161, micro F1: 0.500263631324439, F1 sum: 0.7014713636344823Model was Not saved at epoch 328! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 329, train_loss: 1740.7000209884616, val_loss: 5539.957826646666, micro F1: 0.5044912754373703, F1 sum: 0.7155253198062685Model was Not saved at epoch 329! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 330, train_loss: 1771.2345346344225, val_loss: 4781.390889547765, micro F1: 0.5325788403385862, F1 sum: 0.7569608629153056Model was Not saved at epoch 330! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 331, train_loss: 1751.5115556751164, val_loss: 5124.733786603126, micro F1: 0.5099666360688085, F1 sum: 0.722972950339863Model was Not saved at epoch 331! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 332, train_loss: 1746.3159430629978, val_loss: 5546.542439066495, micro F1: 0.49002667094270386, F1 sum: 0.6899347354285661Model was Not saved at epoch 332! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 333, train_loss: 1734.8100342377684, val_loss: 5045.582931488752, micro F1: 0.5210416611347076, F1 sum: 0.7400672716907745Model was Not saved at epoch 333! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 334, train_loss: 1730.8293414061911, val_loss: 5241.007687097105, micro F1: 0.4997059178092362, F1 sum: 0.704652085785771Model was Not saved at epoch 334! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 335, train_loss: 1735.626123025342, val_loss: 5219.688550957168, micro F1: 0.5141263668435082, F1 sum: 0.7294617778430014Model was Not saved at epoch 335! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 336, train_loss: 1736.7479572195016, val_loss: 4816.287778473149, micro F1: 0.5434716774907429, F1 sum: 0.7713507745610211Model was Not saved at epoch 336! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 337, train_loss: 1727.0515324989005, val_loss: 5251.736910431646, micro F1: 0.5157475514225855, F1 sum: 0.7307561879185717Model was Not saved at epoch 337! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 338, train_loss: 1742.0756813416763, val_loss: 6404.475453309715, micro F1: 0.44537133144052254, F1 sum: 0.614524902513396Model was Not saved at epoch 338! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 339, train_loss: 1720.414878723009, val_loss: 5784.213485700699, micro F1: 0.4837945524245697, F1 sum: 0.6799145880867854Model was Not saved at epoch 339! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 340, train_loss: 1748.1220962564319, val_loss: 5453.734172624536, micro F1: 0.49760808488063046, F1 sum: 0.7001242501817615Model was Not saved at epoch 340! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 341, train_loss: 1739.3835072963334, val_loss: 5068.883445152703, micro F1: 0.5155500483058859, F1 sum: 0.7347087739381095Model was Not saved at epoch 341! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 342, train_loss: 1763.3074656751812, val_loss: 6461.6041238574935, micro F1: 0.4440100711619986, F1 sum: 0.618125187191284Model was Not saved at epoch 342! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 343, train_loss: 1754.069065469435, val_loss: 5697.9065266205, micro F1: 0.5367906881347153, F1 sum: 0.7783187389884005Model was Not saved at epoch 343! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 344, train_loss: 1734.9019522075355, val_loss: 5492.129020082454, micro F1: 0.48876221149851823, F1 sum: 0.6858351561971024Model was Not saved at epoch 344! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 345, train_loss: 1753.7179045324588, val_loss: 5308.605506046054, micro F1: 0.5294337883450984, F1 sum: 0.7565216918847606Model was Not saved at epoch 345! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 346, train_loss: 1736.9342856377173, val_loss: 5136.889749749874, micro F1: 0.5114956441205626, F1 sum: 0.7252725844271026Model was Not saved at epoch 346! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 347, train_loss: 1735.3577778331392, val_loss: 5134.306354060148, micro F1: 0.5158460277190897, F1 sum: 0.7244045708195093Model was Not saved at epoch 347! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 348, train_loss: 1749.1826265457764, val_loss: 5105.647922997983, micro F1: 0.5438973826831595, F1 sum: 0.7752224089591133Model was Not saved at epoch 348! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 349, train_loss: 1764.4164120635062, val_loss: 5344.63793601996, micro F1: 0.5179073812905699, F1 sum: 0.7359144205730141Model was Not saved at epoch 349! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 350, train_loss: 1722.8825507448514, val_loss: 5397.135409681748, micro F1: 0.5336151194724759, F1 sum: 0.7609600292754597Model was Not saved at epoch 350! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 351, train_loss: 1732.256038139617, val_loss: 5686.824335328613, micro F1: 0.5240334097191711, F1 sum: 0.7482569649549684Model was Not saved at epoch 351! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 352, train_loss: 1742.8835824184603, val_loss: 6008.130269280324, micro F1: 0.5319969851446028, F1 sum: 0.7717982024437031Model was Not saved at epoch 352! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 353, train_loss: 1726.4166697880755, val_loss: 5540.028770337813, micro F1: 0.5055605522793485, F1 sum: 0.7170475255325073Model was Not saved at epoch 353! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 354, train_loss: 1726.9822984945802, val_loss: 5482.034888797595, micro F1: 0.4776542428623846, F1 sum: 0.6666554966059266Model was Not saved at epoch 354! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 355, train_loss: 1737.7521676127958, val_loss: 6128.034074014674, micro F1: 0.5162895183676179, F1 sum: 0.7451225882211854Model was Not saved at epoch 355! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 356, train_loss: 1734.9628832442468, val_loss: 5666.540486660476, micro F1: 0.4851207140323822, F1 sum: 0.6840747059124699Model was Not saved at epoch 356! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 357, train_loss: 1740.2279959730326, val_loss: 5727.411103240835, micro F1: 0.5280138031999134, F1 sum: 0.75970957503226Model was Not saved at epoch 357! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 358, train_loss: 1747.5392423933772, val_loss: 7028.659884623872, micro F1: 0.42370401850397077, F1 sum: 0.5813514989766797Model was Not saved at epoch 358! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 359, train_loss: 1757.5294769387795, val_loss: 5434.82752982527, micro F1: 0.4909586265148088, F1 sum: 0.691757660789502Model was Not saved at epoch 359! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 360, train_loss: 1730.3812632041088, val_loss: 4984.5326045760885, micro F1: 0.5144217202080957, F1 sum: 0.7215100768367848Model was Not saved at epoch 360! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 361, train_loss: 1734.5312528842453, val_loss: 5482.120077552585, micro F1: 0.4809379136369292, F1 sum: 0.6754717772896887Model was Not saved at epoch 361! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 362, train_loss: 1738.995524039673, val_loss: 6611.489348191148, micro F1: 0.5011788742810798, F1 sum: 0.7123048805189379Model was Not saved at epoch 362! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 363, train_loss: 1720.1991167372214, val_loss: 4963.710771407932, micro F1: 0.5151322556533463, F1 sum: 0.7300629892042101Model was Not saved at epoch 363! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 364, train_loss: 1705.521317564588, val_loss: 5361.8038855105015, micro F1: 0.5017516477411845, F1 sum: 0.7087473569145004Model was Not saved at epoch 364! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 365, train_loss: 1746.2185723129846, val_loss: 5249.23159837878, micro F1: 0.500207728195043, F1 sum: 0.7011786043736417Model was Not saved at epoch 365! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 366, train_loss: 1737.583347514043, val_loss: 5175.164007814601, micro F1: 0.5151152138568553, F1 sum: 0.7346447935712187Model was Not saved at epoch 366! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 367, train_loss: 1723.9086111315141, val_loss: 5091.613218343507, micro F1: 0.5214483773719015, F1 sum: 0.743874926971815Model was Not saved at epoch 367! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 368, train_loss: 1711.037658747859, val_loss: 5519.677599465164, micro F1: 0.5112709953842568, F1 sum: 0.7293154807088892Model was Not saved at epoch 368! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 369, train_loss: 1733.354762632977, val_loss: 5254.935185851839, micro F1: 0.5142764834531893, F1 sum: 0.7294125083146354Model was Not saved at epoch 369! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 370, train_loss: 1738.0788355935613, val_loss: 5044.988675702674, micro F1: 0.5214697595244312, F1 sum: 0.7341142749547847Model was Not saved at epoch 370! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 371, train_loss: 1728.372860828417, val_loss: 5531.018165056594, micro F1: 0.5057840337763385, F1 sum: 0.715236334248948Model was Not saved at epoch 371! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 372, train_loss: 1703.5230759577437, val_loss: 5464.261423524779, micro F1: 0.5359782907282351, F1 sum: 0.770257445252355Model was Not saved at epoch 372! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 373, train_loss: 1747.4341019640915, val_loss: 6055.082000190548, micro F1: 0.45847264510751606, F1 sum: 0.6376943904942134Model was Not saved at epoch 373! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 374, train_loss: 1706.4585897250645, val_loss: 5184.0126782190055, micro F1: 0.5176040991872166, F1 sum: 0.7317043828342814Model was Not saved at epoch 374! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 375, train_loss: 1726.8449967180024, val_loss: 5328.94070725888, micro F1: 0.514321102486186, F1 sum: 0.7308994429768517Model was Not saved at epoch 375! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 376, train_loss: 1744.960386711483, val_loss: 5105.802594528844, micro F1: 0.5272553610023655, F1 sum: 0.7509681933646789Model was Not saved at epoch 376! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 377, train_loss: 1725.5709103396455, val_loss: 5086.676742648706, micro F1: 0.5169295924385854, F1 sum: 0.7283861754388756Model was Not saved at epoch 377! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 378, train_loss: 1733.7106588317906, val_loss: 5237.406484084204, micro F1: 0.5401937565892392, F1 sum: 0.7771898678787087Model was Not saved at epoch 378! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 379, train_loss: 1718.8049303488024, val_loss: 5584.737495907272, micro F1: 0.5081872640688138, F1 sum: 0.7249098671615608Model was Not saved at epoch 379! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 380, train_loss: 1715.9896491370882, val_loss: 5684.378483953576, micro F1: 0.489049458882558, F1 sum: 0.6940844397319172Model was Not saved at epoch 380! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 381, train_loss: 1725.1854535497741, val_loss: 5431.310868201156, micro F1: 0.499778053429812, F1 sum: 0.6992938529243133Model was Not saved at epoch 381! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 382, train_loss: 1722.9930872382436, val_loss: 5151.712042667592, micro F1: 0.5279473192621178, F1 sum: 0.7529795152340133Model was Not saved at epoch 382! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 383, train_loss: 1726.790358125211, val_loss: 5326.608072888727, micro F1: 0.5350258241800475, F1 sum: 0.7666005386145116Model was Not saved at epoch 383! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 384, train_loss: 1691.898533002872, val_loss: 5782.289595614809, micro F1: 0.49470939742944514, F1 sum: 0.7006856291608226Model was Not saved at epoch 384! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 385, train_loss: 1717.6922317602362, val_loss: 5121.724123794896, micro F1: 0.5181258524166575, F1 sum: 0.7360352488157029Model was Not saved at epoch 385! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 386, train_loss: 1719.0316267910282, val_loss: 5528.225282711598, micro F1: 0.49300460563778564, F1 sum: 0.698447739436233Model was Not saved at epoch 386! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 387, train_loss: 1730.9024486661374, val_loss: 6290.106020363358, micro F1: 0.5258455488913266, F1 sum: 0.7591701151240462Model was Not saved at epoch 387! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 388, train_loss: 1724.395476319264, val_loss: 5408.367727456304, micro F1: 0.5104384026766638, F1 sum: 0.7213070513291617Model was Not saved at epoch 388! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 389, train_loss: 1731.931865269392, val_loss: 5944.161552276152, micro F1: 0.5215114986319046, F1 sum: 0.7541588055392215Model was Not saved at epoch 389! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 390, train_loss: 1718.645912894447, val_loss: 5956.096548664694, micro F1: 0.47141505234127784, F1 sum: 0.6565442841522023Model was Not saved at epoch 390! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 391, train_loss: 1717.3725026816287, val_loss: 5367.5851635246845, micro F1: 0.5102739920684447, F1 sum: 0.7229241017580837Model was Not saved at epoch 391! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 392, train_loss: 1702.5680920133696, val_loss: 5673.7948798884945, micro F1: 0.5046916731807869, F1 sum: 0.7113546824260993Model was Not saved at epoch 392! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 393, train_loss: 1714.3078710258667, val_loss: 6570.986181031913, micro F1: 0.4455388102885081, F1 sum: 0.6161143737801903Model was Not saved at epoch 393! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 394, train_loss: 1716.1931719086178, val_loss: 5184.486103438151, micro F1: 0.5269408067077166, F1 sum: 0.7487952867389444Model was Not saved at epoch 394! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 395, train_loss: 1706.1353623700727, val_loss: 5781.826876918785, micro F1: 0.4793993994758542, F1 sum: 0.66861142925621Model was Not saved at epoch 395! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 396, train_loss: 1705.729840838398, val_loss: 5185.882610579331, micro F1: 0.5418618317441238, F1 sum: 0.7750345178193432Model was Not saved at epoch 396! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 397, train_loss: 1706.8451804542608, val_loss: 5198.273613544491, micro F1: 0.5201742965204176, F1 sum: 0.7419053617618071Model was Not saved at epoch 397! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 398, train_loss: 1729.5270976127704, val_loss: 5054.908800520934, micro F1: 0.5354218912868721, F1 sum: 0.7671321403519565Model was Not saved at epoch 398! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 399, train_loss: 1712.7356621517185, val_loss: 5339.499410280648, micro F1: 0.5112176109561308, F1 sum: 0.7222611313808254Model was Not saved at epoch 399! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
Epoch: 400, train_loss: 1715.668086301204, val_loss: 6117.589522424774, micro F1: 0.46556332011289975, F1 sum: 0.6473508436276727Model was Not saved at epoch 400! F1 sum best: 0.7851450807653104 at step 204; micro F1 best: 0.5451191925199207 at step 204 
